{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GTHA housing market database\n",
    "# OSEMN methodology Step 2: Scrub\n",
    "# Step 2.3 addition of new attributes to the Teranet dataset\n",
    "# (including all records)\n",
    "---\n",
    "\n",
    "This notebook describes Step 2.3 (part of _Step 2: Scrub_ of OSEMN methodology) performed on the Teranet dataset.\n",
    "\n",
    "In this notebook, **records with unreasonably low `consideration_amt` are kept in the dataset.** For the version of this notebook that performs the same steps after removing the records with unreasonably low `consideration_amt`, see `notebooks/2.scrub/2.3_teranet_nonan_new_cols.ipynb`. \n",
    "\n",
    "Step 2.3 focuses on the addition of several new attributes to the Teranet dataset. Plan for the addition of the new attributes is presented below.\n",
    "\n",
    "Previous steps included: \n",
    "\n",
    "* **Step 2.1:** spatial join between the Teranet points and the polygons of GTHA Dissemination Areas (DAs)\n",
    "    \n",
    "    * During step 2.1, Teranet records whose coordinates fall outside of the GTHA boundary (as defined by the DA geometry) have been filtered out (6,803,691 of the original 9,039,241 Teranet records remain in the dataset)\n",
    "     \n",
    "    * In addition to that, three new columns (`OBJECTID`, `DAUID`, and `CSDNAME`) derived from DA attributes have been added to each Teranet transaction\n",
    "\n",
    "    * for details, see `notebooks/2.scrub/2.1_teranet_gtha_spatial_join.ipynb`\n",
    "\n",
    "* **Step 2.2:** correction for consistency of the Teranet records\n",
    "\n",
    "    * column names were converted to lower case\n",
    "    \n",
    "    * inconsistent capitalizations were fixed for columns\n",
    "    \n",
    "        * `municipality`    \n",
    "        * `street_name`\n",
    "        * `street_designation`\n",
    "        * `postal_code` (did not show problems, converted as a preventive measure)\n",
    "        \n",
    "    * columns `province` and `street_suffix` were removed from the dataset\n",
    "    \n",
    "    * new column `street_name_raw` was created: reserve copy of unmodified `street_name`\n",
    "    \n",
    "    * column `street_name` was parsed and cleaned for:\n",
    "    \n",
    "        * `postal_code`\n",
    "        * `unitno`\n",
    "        * `street_number`\n",
    "        * `street_direction`\n",
    "        * `street_designation`\n",
    "        \n",
    "    * plots of the count and percentage of missing values per column were produced\n",
    "    \n",
    "    * inconsistent entries were fixed in the following columns:\n",
    "        \n",
    "        * `street_direction`\n",
    "        * `street_designation`\n",
    "        * `municipality`\n",
    "        * `street_name`\n",
    "        * `unitno`\n",
    "        \n",
    "    * for details, see `notebooks/2.scrub/2.2_teranet_consistency.ipynb`\n",
    "\n",
    "---\n",
    "\n",
    "For description of OSEMN methodology, see `methodology/0.osemn/osemn.pdf`.\n",
    "\n",
    "For background information, description of the Teranet dataset, and its attributes, see `methodology/1.obtain/obtain.pdf`.\n",
    "\n",
    "For description of _Step 2: Scrub_ of OSEMN methodology, see `methodology/2.scrub/scrub.pdf`.\n",
    "\n",
    "For description of the cleanup plan for the Teranet dataset, see `methodology/2.scrub/teranet_cleanup_plan.pdf`.\n",
    "\n",
    "For description of Step 2.1 of the cleanup process, see `notebooks/2.scrub/2.1_teranet_gtha_spatial_join.ipynb`.\n",
    "\n",
    "For description of Step 2.2 of the cleanup process, see `notebooks/2.scrub/2.2_teranet_consistency.ipynb`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Plan for the addition of the new attributes\n",
    "\n",
    "In this notebook, **records with unreasonably low `consideration_amt` are kept in the dataset.** For the version of this notebook that performs the same steps after removing the records with unreasonaby low `consideration_amt`, see `notebooks/2.scrub/2.3_teranet_nonan_new_cols.ipynb`. \n",
    "\n",
    "### Previously added attributes\n",
    "\n",
    "Previously, the following new attributes were created in the Teranet dataset:\n",
    "\n",
    "* attributes produced from the spatial join with DA geometry:\n",
    "\n",
    "    * `objectid`: an identifier for Dissemination Areas (DAs), added as a backup identifier for DAs\n",
    "\n",
    "    * `dauid`: another identifier for Dissemination Areas, indented to be used as the **_foreign key_** linking Teranet records with DAs (will become the **_primary key_** of DA-level datasets (_e.g.,_ DA-level Census data)\n",
    "    \n",
    "    * `csdname`: municipality name according to Census data (DA-level)\n",
    "\n",
    "These attributes were added to each Teranet record via a spatial join of Teranet points with the polygons of Dissemination Areas (DAs) during Step 2.1 of the cleanup process\n",
    "\n",
    "* attributes produced during the correction of Teranet records for consistency:\n",
    "\n",
    "    * `street_name_raw`: unmodified reserve copy of the original `street_name` from the Teranet dataset\n",
    "\n",
    "### Attributes to be added in this step\n",
    "\n",
    "In this step, the following attributes will be added to the Teranet dataset:\n",
    "\n",
    "* surrogate key:\n",
    "\n",
    "    * `transaction_id`: unique identifier for each Teranet transaction \n",
    "    \n",
    "Essentially, a simple range index, which represents the row number of a record in the full Teranet dataset (filtered to include only GTHA records), ordered by date (from earliest to latest) and `pin`\n",
    "    \n",
    "* attributes for display\n",
    "\n",
    "    * `date_disp`: `registration_date` converted to `datetime.date` data type to exclude the timestamp (original `registration_date` is stored in NumPy's `datetime64` format to allow more efficient datetime operations)\n",
    "    \n",
    "    * `price_disp`: `consideration_amt` formatted to include thousands separator (_e.g.,_ '3,455,122') and stored as a string, for display purposes\n",
    "    \n",
    "* attributes for record grouping\n",
    "    \n",
    "    * `year`: year parsed from `registration_date`, to simplify record grouping\n",
    "    \n",
    "    * `year_month`: year and month parsed from `registration_date`, to simplify record grouping\n",
    "    \n",
    "    * `year3`: `registration_date` parsed for 3-year intervals (_e.g.,_ '2014-2016'), to simplify record grouping\n",
    "    \n",
    "    * `year5`: `registration_date` parsed for 5-year intervals (_e.g.,_ '2012-2016'), to simplify record grouping\n",
    "    \n",
    "    * `year10`: `registration_date` parsed for 3-year intervals (_e.g.,_ '2007-2017'), to simplify record grouping\n",
    "    \n",
    "    * `xy`: `x` and `y` coordinates concatenated together (_e.g.,_ '43.098324_-79.234235'), can be used to identify and group records by their coordinate pairs\n",
    "    \n",
    "* correction of `consideration_amt` for inflation    \n",
    "    \n",
    "    * `price_infl`: `consideration_amt` corrected for inflation\n",
    "    \n",
    "* exploratory attributes\n",
    "\n",
    "    * `pin/xy_total_sales`: total records for this `pin`/`xy`\n",
    "\n",
    "    * `pin/xy_prev_sales`: previous records from this `pin`/`xy` (not counting current transaction)\n",
    "\n",
    "    * `pin/xy_price_cum_sum`: cumulative price of all records to date from this `pin`/`xy`\n",
    "\n",
    "    * `pin/xy_price_pct_change`: price percentage change compared to previous record from this `pin`/`xy`\n",
    "\n",
    "    * `price_da_pct_change`: price percentage change compared to previous record from this DA (by `da_id`)\n",
    "\n",
    "    * `pin/xy_years_since_last_sale`: years since last sale from this `pin`/`xy`\n",
    "\n",
    "    * `da_days_since_last_sale`, `da_years_since_last_sale`: days or years since last sale from this DA (by `da_id`)\n",
    "\n",
    "    * `sale_next_6m/1y/3y`: \"looks into the future\" to see whether there is another transaction from this `pin`/`xy` within the given time horizon (6 months, 1 year, 3 years)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Import dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['3_Teranet_new_cols.csv',\n",
       " 'epoi_gtha13',\n",
       " '2_Teranet_consistent.csv',\n",
       " '1.2_Teranet_DA_TAZ_cols.csv',\n",
       " '1.1_Teranet_DA_cols.csv',\n",
       " '1.3_Teranet_DA_TAZ_LU.csv',\n",
       " 'ParcelLandUse.zip',\n",
       " 'ParcelLandUse',\n",
       " 'HHSaleHistory.csv',\n",
       " '3_Teranet_nonan_new_cols.csv',\n",
       " 'GTAjoinedLanduseSales']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path = '../../data/teranet/'\n",
    "os.listdir(data_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Teranet data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- DataFrame loaded\n",
      "in 1,117.42 seconds (18.62 minutes)\n",
      "with 6,803,767 rows\n",
      "and 21 columns\n",
      "-- Column names:\n",
      " Index(['lro_num', 'pin', 'consideration_amt', 'registration_date',\n",
      "       'postal_code', 'unitno', 'street_name', 'street_designation',\n",
      "       'street_direction', 'municipality', 'street_number', 'x', 'y', 'dauid',\n",
      "       'csduid', 'csdname', 'taz_o', 'pin_lu', 'landuse', 'prop_code',\n",
      "       'street_name_raw'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "t = time()\n",
    "\n",
    "df = pd.read_csv(data_path + '2_Teranet_consistent.csv',\n",
    "                 parse_dates=['registration_date'], low_memory=False)\n",
    "elapsed = time() - t\n",
    "print(\"----- DataFrame loaded\"\n",
    "      \"\\nin {0:,.2f} seconds ({1:.2f} minutes)\".format(elapsed, elapsed / 60) + \n",
    "      \"\\nwith {0:,} rows\\nand {1:,} columns\"\n",
    "      .format(df.shape[0], df.shape[1]) + \n",
    "      \"\\n-- Column names:\\n\", df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6803767 entries, 0 to 6803766\n",
      "Data columns (total 21 columns):\n",
      "lro_num               6803767 non-null int64\n",
      "pin                   6803767 non-null int64\n",
      "consideration_amt     6803767 non-null float64\n",
      "registration_date     6803767 non-null datetime64[ns]\n",
      "postal_code           6233378 non-null object\n",
      "unitno                1572961 non-null object\n",
      "street_name           6598370 non-null object\n",
      "street_designation    6522471 non-null object\n",
      "street_direction      683462 non-null object\n",
      "municipality          6799752 non-null object\n",
      "street_number         6594376 non-null object\n",
      "x                     6803767 non-null float64\n",
      "y                     6803767 non-null float64\n",
      "dauid                 6803767 non-null int64\n",
      "csduid                6803767 non-null int64\n",
      "csdname               6803767 non-null object\n",
      "taz_o                 6802628 non-null float64\n",
      "pin_lu                6491804 non-null float64\n",
      "landuse               6009136 non-null float64\n",
      "prop_code             482676 non-null float64\n",
      "street_name_raw       6598370 non-null object\n",
      "dtypes: datetime64[ns](1), float64(7), int64(4), object(9)\n",
      "memory usage: 1.1+ GB\n"
     ]
    }
   ],
   "source": [
    "df.info(null_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Surrogate key\n",
    "\n",
    "### Add attribute `transaction_id`\n",
    "Attribute `transaction_id` is intended as a unique identifier for each record in the Teranet dataset. It will be used as the **_primary key_** for records in Teranet table in the proposed GTHA housing market database. It is produced as a surrogate key, as no other attribute or combination of attributes in the Teranet dataset allows the records to be uniquely identified. \n",
    "    \n",
    "`transaction_id` is essentially a simple range index, which represents the row number of a record in the full Teranet dataset (filtered to include only GTHA records), ordered by date (from earliest to latest) and `pin`\n",
    "\n",
    "#### Order Teranet records by `registration_date` and `pin`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame was resorted by 'registration_date' and 'pin'.\n"
     ]
    }
   ],
   "source": [
    "df = df.sort_values(['registration_date', 'pin'])\n",
    "print(\"DataFrame was resorted by 'registration_date' and 'pin'.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Insert the new column `transaction_id`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New column 'transaction_id' was added to the DataFrame.\n"
     ]
    }
   ],
   "source": [
    "df.insert(0, \"transaction_id\", np.arange(len(df)))\n",
    "print(\"New column 'transaction_id' was added to the DataFrame.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attributes for display\n",
    "\n",
    "### Add attribute `date_disp`\n",
    "Since Teranet records do not carry any actual timestamp (each record has a timestamp of '00:00:00'), a new column `date_disp` is created from `registration_date` to show only dates. The new column `date_disp` has a data type of `datetime.date`, while the original column `registration_date` is stored in NumPy's `datetime64` data type, which allows more efficient datetime operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New column 'date_disp' was added to the DataFrame.\n"
     ]
    }
   ],
   "source": [
    "df['date_disp'] = df['registration_date'].dt.date\n",
    "print(\"New column 'date_disp' was added to the DataFrame.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Add attribute `price_disp`\n",
    "A new column `price_disp` is created from values of `consideration_amt` formatted to include thousands separator (_e.g.,_ '3,455,122') and stored as a string, for display purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New column 'price_disp' was added to the DataFrame.\n"
     ]
    }
   ],
   "source": [
    "df['price_disp'] = df['consideration_amt'].apply(lambda x: '{:,}'.format(x))\n",
    "print(\"New column 'price_disp' was added to the DataFrame.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add attribute `year`\n",
    "The new attribute `year` is parsed from `registration_date` and stored as a string, to simplify record grouping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New column 'year' was added to the DataFrame.\n"
     ]
    }
   ],
   "source": [
    "df['year'] = df['date_disp'].astype('str').apply(lambda x: x[:4])\n",
    "print(\"New column 'year' was added to the DataFrame.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add attribute `year_month`\n",
    "The new attribute `year_month` is parsed from `date_disp` and stored as a string, to simplify record grouping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New column 'year_month' was added to the DataFrame.\n"
     ]
    }
   ],
   "source": [
    "df['year_month'] = df['date_disp'].astype('str').apply(lambda x: x[:7])\n",
    "print(\"New column 'year_month' was added to the DataFrame.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add attribute `year3`\n",
    "The new attribute `year3` is created from the column `year` parsed for 3-year intervals (_e.g.,_ '2014-2016') and stored as a string, to simplify record grouping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "t = time()\n",
    "\n",
    "df['year3'] = df['year']\n",
    "\n",
    "year_list = df['year'].unique()\n",
    "\n",
    "i = 0\n",
    "ylist = []\n",
    "for year in year_list:\n",
    "    ylist.append(year)\n",
    "    i += 1\n",
    "    if i == 3:\n",
    "        df['year3'] = df['year3'].str.replace('^' + ylist[0] + '$|^' + ylist[1] + '$|^' + ylist[2] + '$', \n",
    "                                              ylist[0] + '-' + ylist[2])\n",
    "        ylist = []\n",
    "        i = 0\n",
    "\n",
    "elapsed = time() - t\n",
    "\n",
    "print(\"New column 'year3' was added to the DataFrame. Took {0:,.2f} seconds ({1:.2f} minutes).\"\n",
    "      .format(elapsed, elapsed / 60))\n",
    "df['year3'].value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Add attribute `year5`\n",
    "The new attribute `year5` is created from the column `year` parsed for 5-year intervals (_e.g.,_ '2012-2016') and stored as a string, to simplify record grouping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "t = time()\n",
    "\n",
    "df['year5'] = df['year']\n",
    "\n",
    "year_list = df['year'].unique()[1:] # skipping first year (1805) to match the length of a 5-year window\n",
    "\n",
    "i = 0\n",
    "ylist = []\n",
    "for year in year_list:\n",
    "    ylist.append(year)\n",
    "    i += 1\n",
    "    if i == 5:\n",
    "        df['year5'] = df['year5'].str.replace('^' + ylist[0] + '$|^' + ylist[1] + '$|^' + ylist[2] + '$|^' +\n",
    "                                              ylist[3] + '$|^' + ylist[4] + '$', \n",
    "                                              ylist[0] + '-' + ylist[4])\n",
    "        ylist = []\n",
    "        i = 0\n",
    "\n",
    "elapsed = time() - t\n",
    "\n",
    "print(\"New column 'year5' was added to the DataFrame. Took {0:,.2f} seconds ({1:.2f} minutes).\"\n",
    "      .format(elapsed, elapsed / 60))\n",
    "df['year5'].value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add attribute `year10`\n",
    "The new attribute `year10` is created from the column `year` parsed for 5-year intervals (_e.g.,_ '2014-2017') and stored as a string, to simplify record grouping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "t = time()\n",
    "\n",
    "df['year10'] = df['year']\n",
    "\n",
    "year_list = df['year'].unique()[1:] # skipping first year (1805) to match the length of a 10-year window\n",
    "\n",
    "i = 0\n",
    "ylist = []\n",
    "for year in year_list:\n",
    "    ylist.append(year)\n",
    "    i += 1\n",
    "    if i == 10:\n",
    "        df['year10'] = df['year10'].str.replace('^' + ylist[0] + '$|^' + ylist[1] + '$|^' + ylist[2] + '$|^' +\n",
    "                                                ylist[3] + '$|^' + ylist[4] + '$|^' + ylist[5] + '$|^' + ylist[6] +\n",
    "                                                '$|^' + ylist[7] + '$|^' + ylist[8] + '$|^' + ylist[9] + '$', \n",
    "                                                ylist[0] + '-' + ylist[9])\n",
    "        ylist = []\n",
    "        i = 0\n",
    "\n",
    "elapsed = time() - t\n",
    "\n",
    "print(\"New column 'year10' was added to the DataFrame. Took {0:,.2f} seconds ({1:.2f} minutes).\"\n",
    "      .format(elapsed, elapsed / 60))\n",
    "df['year10'].value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Add attribute `xy`\n",
    "\n",
    "The new attribute `xy` is produced by concatenating `x` and `y` together (_e.g.,_ '-79.9774202446447_43.203290987723'), it can be used to identify and group records by their coordinate pairs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df['xy'] = df['x'].astype('str') + '_' + df['y'].astype('str')\n",
    "print(\"New column 'xy' was added to the DataFrame.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correction of `consideration_amt` for inflation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Exploratory attributes\n",
    "\n",
    "### Add column `total_sales`\n",
    "Total records for each pin, generated as a separate DataFrame `df_pin` which represents Teranet records grouped and indexed by `pin`.\n",
    "\n",
    "`total_sales_pin` is added as a new column for Teranet records via a merge operation on `pin`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# group records by `pin`\n",
    "t = time()\n",
    "pin_counts = \\\n",
    "    df.groupby('pin')['consideration_amt'].count()\n",
    "pin_counts.name = 'pin_total_sales'\n",
    "df = pd.merge(df, pin_counts, on='pin')\n",
    "elapsed = time() - t\n",
    "print(\"\\nNew column 'pin_total_sales' \"\n",
    "      \"added to the DataFrame!\"\n",
    "      \"\\ntook {0:.2f} seconds.\".format(elapsed))\n",
    "\n",
    "# group records by `xy` coordinate pairs\n",
    "t = time()\n",
    "xy_counts = \\\n",
    "    df.groupby('xy')['consideration_amt'].count()\n",
    "xy_counts.name = 'xy_total_sales'\n",
    "df = pd.merge(df, xy_counts, on='xy')\n",
    "elapsed = time() - t\n",
    "print(\"\\nNew column 'xy_total_sales' \"\n",
    "      \"added to the DataFrame!\"\n",
    "      \"\\ntook {0:.2f} seconds.\".format(elapsed))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add column `prev_sales`\n",
    "New columns are added to Teranet records capturing, for each transaction, a rolling count of previous records from this `pin` or `xy` coordinate pair."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df['count'] = 1 # used to produce rolling counts per `pin` and `xy`\n",
    "\n",
    "# group by `pin`\n",
    "t = time()\n",
    "df['pin_prev_sales'] = \\\n",
    "    df.sort_values(['pin', 'registration_date'])\\\n",
    "    .groupby('pin')['count'].cumsum() - 1\n",
    "elapsed = time() - t\n",
    "print(\"\\nNew column 'pin_prev_sales' \"\n",
    "      \"added to the DataFrame!\"\n",
    "      \"\\ntook {0:.2f} seconds.\".format(elapsed))\n",
    "\n",
    "# group by xy pairs\n",
    "t = time()\n",
    "df['xy_prev_sales'] = \\\n",
    "    df.sort_values(['xy', 'registration_date'])\\\n",
    "    .groupby('xy')['count'].cumsum() - 1\n",
    "elapsed = time() - t\n",
    "print(\"\\nNew column 'xy_prev_sales' \"\n",
    "      \"added to the DataFrame!\"\n",
    "      \"\\ntook {0:.2f} seconds.\".format(elapsed))\n",
    "\n",
    "df = df.drop('count', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add columns `price_cum_sum` and `price_pct_change`\n",
    "New columns are added to Teranet records capturing, for each transaction, a rolling sum of price from previous records from this `pin` or `xy` coordinate pair, and `pct_change` compared to previous transaction from this `pin` or `xy` pair."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# `price_cum_sum`\n",
    "# group records by `pin`\n",
    "t = time()\n",
    "df['pin_price_cum_sum'] = \\\n",
    "    df.sort_values(['pin', 'registration_date'])\\\n",
    "    .groupby('pin')['consideration_amt'].cumsum()\n",
    "elapsed = time() - t\n",
    "print(\"\\nNew column 'pin_price_cum_sum' \"\n",
    "      \"added to the DataFrame!\"\n",
    "      \"\\ntook {0:.2f} seconds.\".format(elapsed))\n",
    "# group records by `xy` pairs\n",
    "t = time()\n",
    "df['xy_price_cum_sum'] = \\\n",
    "    df.sort_values(['xy', 'registration_date'])\\\n",
    "    .groupby('xy')['consideration_amt'].cumsum()\n",
    "elapsed = time() - t\n",
    "print(\"\\nNew column 'xy_price_cum_sum' \"\n",
    "      \"added to the DataFrame!\"\n",
    "      \"\\ntook {0:.2f} seconds.\".format(elapsed))\n",
    "\n",
    "# `price_pct_change`\n",
    "# group records by `pin`\n",
    "t = time()\n",
    "df['pin_price_pct_change'] = \\\n",
    "    df.sort_values(['pin', 'registration_date'])\\\n",
    "    .groupby('pin')['consideration_amt'].pct_change()\n",
    "elapsed = time() - t\n",
    "print(\"\\nNew column 'pin_price_pct_change' \"\n",
    "      \"added to the DataFrame!\"\n",
    "      \"\\ntook {0:.2f} seconds.\".format(elapsed))\n",
    "# group records by `xy`\n",
    "t = time()\n",
    "df['xy_price_pct_change'] = \\\n",
    "    df.sort_values(['xy', 'registration_date'])\\\n",
    "    .groupby('xy')['consideration_amt'].pct_change()\n",
    "elapsed = time() - t\n",
    "print(\"\\nNew column 'xy_price_pct_change' \"\n",
    "      \"added to the DataFrame!\"\n",
    "      \"\\ntook {0:.2f} seconds.\".format(elapsed))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add column `price_da_pct_change`\n",
    "New column is added to Teranet records capturing, for each transaction, percentage change in price compared to the previous record from this `da_id`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# add column 'price_da_pct_change' to Teranet records DataFrame \n",
    "t = time()\n",
    "df['price_da_pct_change'] = \\\n",
    "    df.sort_values(['dauid', 'registration_date'])\\\n",
    "    .groupby('dauid')['consideration_amt'].pct_change()\n",
    "elapsed = time() - t\n",
    "print(\"\\nNew column 'price_da_pct_change' \"\n",
    "      \"added to the DataFrame!\"\n",
    "      \"\\ntook {0:.2f} seconds.\".format(elapsed))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add columns `years_since_last_sale`\n",
    "New columns are added to Teranet records capturing, for each transaction, years passed since the previous record from this `pin` or `xy` coordinate pair."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "t = time()\n",
    "df['pin_years_since_last_sale'] = \\\n",
    "    df.sort_values(['pin', 'registration_date'])\\\n",
    "      .groupby('pin')['registration_date']\\\n",
    "        .diff().dt.days / 365\n",
    "elapsed = time() - t\n",
    "print(\"New column 'pin_years_since_last_sale' \"\n",
    "      \"added to the DataFrame!\"\n",
    "      \"\\ntook {0:.2f} seconds ({1:.2f} minutes).\".format(elapsed, elapsed / 60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "t = time()\n",
    "df['xy_years_since_last_sale'] = \\\n",
    "    df.sort_values(['xy', 'registration_date'])\\\n",
    "      .groupby('xy')['registration_date']\\\n",
    "        .diff().dt.days / 365\n",
    "elapsed = time() - t\n",
    "print(\"New column 'xy_years_since_last_sale' \"\n",
    "      \"added to the DataFrame!\"\n",
    "      \"\\ntook {0:.2f} seconds ({1:.2f} minutes).\".format(elapsed, elapsed / 60))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add columns `da_days_since_last_sale` and `da_years_since_last_sale`\n",
    "New columns are added to Teranet records capturing, for each transaction, years passed since the previous record from this `pin` or `xy` coordinate pair."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# add column 'da_days_since_last_sale' to Teranet records DataFrame \n",
    "t = time()\n",
    "df['da_days_since_last_sale'] = \\\n",
    "    df.sort_values(['dauid', 'registration_date'])\\\n",
    "      .groupby('dauid')['registration_date']\\\n",
    "        .diff().dt.days\n",
    "elapsed = time() - t\n",
    "print(\"New column 'da_days_since_last_sale' \"\n",
    "      \"added to the DataFrame!\"\n",
    "      \"\\ntook {0:.2f} seconds.\".format(elapsed))\n",
    "# add column 'da_years_since_last_sale' to Teranet records DataFrame \n",
    "t = time()\n",
    "df['da_years_since_last_sale'] = \\\n",
    "    df.sort_values(['dauid', 'registration_date'])\\\n",
    "      .groupby('dauid')['registration_date']\\\n",
    "        .diff().dt.days / 365\n",
    "elapsed = time() - t\n",
    "print(\"New column 'da_years_since_last_sale' \"\n",
    "      \"added to the DataFrame!\"\n",
    "      \"\\ntook {0:.2f} seconds.\".format(elapsed))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add columns `sale_next_6m/1y/3y` per `pin` and `xy`\n",
    "New columns are added to Teranet records capturing, for each transaction, whether there would be another transaction in the future from this `pin`, `xy`, or `da_id`\n",
    "\n",
    "Time horizons used: 6 months, 1 year, 3 years."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# create a new column, marks True if next 'day_diff' <= 5\n",
    "# group records by `pin`\n",
    "t = time()\n",
    "df = df.sort_values(['pin', 'registration_date'])\n",
    "df['pin_sale_next_6m'] = \\\n",
    "    df['pin_years_since_last_sale'].shift(-1) <= 0.5\n",
    "df['pin_sale_next_1y'] = \\\n",
    "    df['pin_years_since_last_sale'].shift(-1) <= 1\n",
    "df['pin_sale_next_3y'] = \\\n",
    "    df['pin_years_since_last_sale'].shift(-1) <= 3\n",
    "elapsed = time() - t\n",
    "print(\"New columns 'pin_sale_next_..' \"\n",
    "      \"added to the DataFrame!\"\n",
    "      \"\\ntook {0:.2f} seconds.\".format(elapsed))\n",
    "\n",
    "# group records by `xy`\n",
    "t = time()\n",
    "df = df.sort_values(['xy', 'registration_date'])\n",
    "df['xy_sale_next_6m'] = \\\n",
    "    df['xy_years_since_last_sale'].shift(-1) <= 0.5\n",
    "df['xy_sale_next_1y'] = \\\n",
    "    df['xy_years_since_last_sale'].shift(-1) <= 1\n",
    "df['xy_sale_next_3y'] = \\\n",
    "    df['xy_years_since_last_sale'].shift(-1) <= 3\n",
    "elapsed = time() - t\n",
    "print(\"New columns 'xy_sale_next_..' \"\n",
    "      \"added to the DataFrame!\"\n",
    "      \"\\ntook {0:.2f} seconds.\".format(elapsed))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Price correction for inflation\n",
    "Transaction prices are corrected for inflation to 2016 prices using the guidelines provided in the [Inflation Calculator](https://www.bankofcanada.ca/rates/related/inflation-calculator/) supplied by the Bank of Canada."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load correction coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "infl_coefs = pd.read_excel(data_path + '../misc/Infl_adjustment.xlsx')\n",
    "infl_coefs = infl_coefs.T\n",
    "infl_coefs.columns = infl_coefs.iloc[0]\n",
    "infl_coefs = infl_coefs.drop('YEAR')\n",
    "print(infl_coefs.iloc[0])\n",
    "infl_coefs = infl_coefs.iloc[:, 0]\n",
    "infl_coefs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correct consideration amount for inflation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "year_list = infl_coefs.index\n",
    "for year in year_list:\n",
    "    mask1 = df['year'] == str(year)\n",
    "    mask2 = df['consideration_amt'].isnull()\n",
    "    price_raw = df.loc[mask1 & ~mask2, 'consideration_amt']\n",
    "    df.loc[mask1 & ~mask2, 'price_2016'] = ((infl_coefs[year] / 100) + 1) * price_raw\n",
    "    print(\"Corrected prices from {0} for inflation.\".format(year))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save results to a new .csv file\n",
    "Teranet dataset without NaN records and with 12 new columns is saved as:\n",
    "`data/HHSaleHistory_cleaned_v0.9_GTHA_DA_with_cols_v0.9.csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "save_path = data_path + '3_Teranet_new_cols.csv'\n",
    "t = time()\n",
    "df.to_csv(save_path, index=False)\n",
    "elapsed = time() - t\n",
    "print(\"DataFrame saved to file:\\n\", save_path,\n",
    "      \"\\ntook {0:.2f} seconds ({1:.2f} minutes).\".format(elapsed, elapsed / 60))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
