{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GTHA housing market database\n",
    "# OSEMN methodology Step 2: Scrub\n",
    "# Step 2.3 addition of new attributes to the Teranet dataset\n",
    "# (including all records)\n",
    "---\n",
    "\n",
    "This notebook describes Step 2.3 (part of _Step 2: Scrub_ of OSEMN methodology) performed on the Teranet dataset.\n",
    "\n",
    "In this notebook, **records with unreasonably low `consideration_amt` are kept in the dataset.** For the version of this notebook that performs the same steps after removing the records with unreasonably low `consideration_amt`, see `notebooks/2.scrub/2.3_teranet_nonan_new_cols.ipynb`. \n",
    "\n",
    "Step 2.3 focuses on the addition of several new attributes to the Teranet dataset. Plan for the addition of the new attributes is presented below.\n",
    "\n",
    "Previous steps included: \n",
    "\n",
    "* **Step 2.1:** spatial join between the Teranet points and the polygons of GTHA Dissemination Areas (DAs)\n",
    "    \n",
    "    * During step 2.1, Teranet records whose coordinates fall outside of the GTHA boundary (as defined by the DA geometry) have been filtered out (6,803,691 of the original 9,039,241 Teranet records remain in the dataset)\n",
    "     \n",
    "    * In addition to that, three new columns (`OBJECTID`, `DAUID`, and `CSDNAME`) derived from DA attributes have been added to each Teranet transaction\n",
    "\n",
    "    * for details, see `notebooks/2.scrub/2.1_teranet_gtha_spatial_join.ipynb`\n",
    "\n",
    "* **Step 2.2:** correction for consistency of the Teranet records\n",
    "\n",
    "    * column names were converted to lower case\n",
    "    \n",
    "    * inconsistent capitalizations were fixed for columns\n",
    "    \n",
    "        * `municipality`    \n",
    "        * `street_name`\n",
    "        * `street_designation`\n",
    "        * `postal_code` (did not show problems, converted as a preventive measure)\n",
    "        \n",
    "    * columns `province` and `street_suffix` were removed from the dataset\n",
    "    \n",
    "    * new column `street_name_raw` was created: reserve copy of unmodified `street_name`\n",
    "    \n",
    "    * column `street_name` was parsed and cleaned for:\n",
    "    \n",
    "        * `postal_code`\n",
    "        * `unitno`\n",
    "        * `street_number`\n",
    "        * `street_direction`\n",
    "        * `street_designation`\n",
    "        \n",
    "    * plots of the count and percentage of missing values per column were produced\n",
    "    \n",
    "    * inconsistent entries were fixed in the following columns:\n",
    "        \n",
    "        * `street_direction`\n",
    "        * `street_designation`\n",
    "        * `municipality`\n",
    "        * `street_name`\n",
    "        * `unitno`\n",
    "        \n",
    "    * for details, see `notebooks/2.scrub/2.2_teranet_consistency.ipynb`\n",
    "\n",
    "---\n",
    "\n",
    "For description of OSEMN methodology, see `methodology/0.osemn/osemn.pdf`.\n",
    "\n",
    "For background information, description of the Teranet dataset, and its attributes, see `methodology/1.obtain/obtain.pdf`.\n",
    "\n",
    "For description of _Step 2: Scrub_ of OSEMN methodology, see `methodology/2.scrub/scrub.pdf`.\n",
    "\n",
    "For description of the cleanup plan for the Teranet dataset, see `methodology/2.scrub/teranet_cleanup_plan.pdf`.\n",
    "\n",
    "For description of Step 2.1 of the cleanup process, see `notebooks/2.scrub/2.1_teranet_gtha_spatial_join.ipynb`.\n",
    "\n",
    "For description of Step 2.2 of the cleanup process, see `notebooks/2.scrub/2.2_teranet_consistency.ipynb`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Plan for the addition of the new attributes\n",
    "\n",
    "In this notebook, **records with unreasonably low `consideration_amt` are kept in the dataset.** For the version of this notebook that performs the same steps after removing the records with unreasonaby low `consideration_amt`, see `notebooks/2.scrub/2.3_teranet_nonan_new_cols.ipynb`. \n",
    "\n",
    "### Previously added attributes\n",
    "\n",
    "Previously, the following new attributes were created in the Teranet dataset:\n",
    "\n",
    "* attributes produced from the spatial join with DA geometry:\n",
    "\n",
    "    * `objectid`: an identifier for Dissemination Areas (DAs), added as a backup identifier for DAs\n",
    "\n",
    "    * `dauid`: another identifier for Dissemination Areas, indented to be used as the **_foreign key_** linking Teranet records with DAs (will become the **_primary key_** of DA-level datasets (_e.g.,_ DA-level Census data)\n",
    "    \n",
    "    * `csdname`: municipality name according to Census data (DA-level)\n",
    "\n",
    "These attributes were added to each Teranet record via a spatial join of Teranet points with the polygons of Dissemination Areas (DAs) during Step 2.1 of the cleanup process\n",
    "\n",
    "* attributes produced during the correction of Teranet records for consistency:\n",
    "\n",
    "    * `street_name_raw`: unmodified reserve copy of the original `street_name` from the Teranet dataset\n",
    "\n",
    "### Attributes to be added in this step\n",
    "\n",
    "In this step, the following attributes will be added to the Teranet dataset:\n",
    "\n",
    "* surrogate key:\n",
    "\n",
    "    * `transaction_id`: unique identifier for each Teranet transaction \n",
    "    \n",
    "Essentially, a simple range index, which represents the row number of a record in the full Teranet dataset (filtered to include only GTHA records), ordered by date (from earliest to latest) and `pin`\n",
    "    \n",
    "* attributes for display\n",
    "\n",
    "    * `date_disp`: `registration_date` converted to `datetime.date` data type to exclude the timestamp (original `registration_date` is stored in NumPy's `datetime64` format to allow more efficient datetime operations)\n",
    "    \n",
    "    * `price_disp`: `consideration_amt` formatted to include thousands separator (_e.g.,_ '3,455,122') and stored as a string, for display purposes\n",
    "    \n",
    "* attributes for record grouping\n",
    "    \n",
    "    * `year`: year parsed from `registration_date`, to simplify record grouping\n",
    "    \n",
    "    * `year_month`: year and month parsed from `registration_date`, to simplify record grouping\n",
    "    \n",
    "    * `year3`: `registration_date` parsed for 3-year intervals (_e.g.,_ '2014-2016'), to simplify record grouping\n",
    "    \n",
    "    * `year5`: `registration_date` parsed for 5-year intervals (_e.g.,_ '2012-2016'), to simplify record grouping\n",
    "    \n",
    "    * `year10`: `registration_date` parsed for 3-year intervals (_e.g.,_ '2007-2017'), to simplify record grouping\n",
    "    \n",
    "    * `xy`: `x` and `y` coordinates concatenated together (_e.g.,_ '43.098324_-79.234235'), can be used to identify and group records by their coordinate pairs\n",
    "    \n",
    "* correction of `consideration_amt` for inflation    \n",
    "    \n",
    "    * `price_infl`: `consideration_amt` corrected for inflation\n",
    "    \n",
    "* exploratory attributes\n",
    "\n",
    "    * `pin/xy_total_sales`: total records for this `pin`/`xy`\n",
    "\n",
    "    * `pin/xy_prev_sales`: previous records from this `pin`/`xy` (not counting current transaction)\n",
    "\n",
    "    * `pin/xy_price_cum_sum`: cumulative price of all records to date from this `pin`/`xy`\n",
    "\n",
    "    * `pin/xy_price_pct_change`: price percentage change compared to previous record from this `pin`/`xy`\n",
    "\n",
    "    * `price_da_pct_change`: price percentage change compared to previous record from this DA (by `da_id`)\n",
    "\n",
    "    * `pin/xy_years_since_last_sale`: years since last sale from this `pin`/`xy`\n",
    "\n",
    "    * `da_days_since_last_sale`, `da_years_since_last_sale`: days or years since last sale from this DA (by `da_id`)\n",
    "\n",
    "    * `sale_next_6m/1y/3y`: \"looks into the future\" to see whether there is another transaction from this `pin`/`xy` within the given time horizon (6 months, 1 year, 3 years)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Import dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Teranet_DA_cols.csv',\n",
       " 'Teranet_consistent.csv',\n",
       " 'Teranet_with_DA_cols.csv',\n",
       " 'Teranet_new_cols.csv',\n",
       " 'Teranet_DA_TAZ_cols.csv',\n",
       " 'Teranet_nonan_new_cols.csv',\n",
       " 'HHSaleHistory.csv']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path = '../../data/teranet/'\n",
    "os.listdir(data_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Teranet data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- DataFrame loaded\n",
      "in 29.11 seconds (0.49 minutes)\n",
      "with 6,803,756 rows\n",
      "and 19 columns\n",
      "-- Column names:\n",
      " Index(['lro_num', 'pin', 'consideration_amt', 'registration_date',\n",
      "       'postal_code', 'unitno', 'street_name', 'street_designation',\n",
      "       'street_direction', 'municipality', 'street_number', 'x', 'y',\n",
      "       'da_objectid', 'dauid', 'csdname', 'taz_objectid', 'taz_o',\n",
      "       'street_name_raw'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "t = time()\n",
    "\n",
    "df = pd.read_csv(data_path + 'Teranet_consistent.csv',\n",
    "                 parse_dates=['registration_date'], low_memory=False)\n",
    "elapsed = time() - t\n",
    "print(\"----- DataFrame loaded\"\n",
    "      \"\\nin {0:,.2f} seconds ({1:.2f} minutes)\".format(elapsed, elapsed / 60) + \n",
    "      \"\\nwith {0:,} rows\\nand {1:,} columns\"\n",
    "      .format(df.shape[0], df.shape[1]) + \n",
    "      \"\\n-- Column names:\\n\", df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6803756 entries, 0 to 6803755\n",
      "Data columns (total 19 columns):\n",
      "lro_num               6803756 non-null int64\n",
      "pin                   6803756 non-null int64\n",
      "consideration_amt     6803756 non-null float64\n",
      "registration_date     6803756 non-null datetime64[ns]\n",
      "postal_code           6233369 non-null object\n",
      "unitno                1572960 non-null object\n",
      "street_name           6598361 non-null object\n",
      "street_designation    6522462 non-null object\n",
      "street_direction      683462 non-null object\n",
      "municipality          6799741 non-null object\n",
      "street_number         6594367 non-null object\n",
      "x                     6803756 non-null float64\n",
      "y                     6803756 non-null float64\n",
      "da_objectid           6803756 non-null int64\n",
      "dauid                 6803756 non-null int64\n",
      "csdname               6803756 non-null object\n",
      "taz_objectid          6802617 non-null float64\n",
      "taz_o                 6802617 non-null float64\n",
      "street_name_raw       6598361 non-null object\n",
      "dtypes: datetime64[ns](1), float64(5), int64(4), object(9)\n",
      "memory usage: 986.3+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info(null_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Surrogate key\n",
    "\n",
    "### Add attribute `transaction_id`\n",
    "Attribute `transaction_id` is intended as a unique identifier for each record in the Teranet dataset. It will be used as the **_primary key_** for records in Teranet table in the proposed GTHA housing market database. It is produced as a surrogate key, as no other attribute or combination of attributes in the Teranet dataset allows the records to be uniquely identified. \n",
    "    \n",
    "`transaction_id` is essentially a simple range index, which represents the row number of a record in the full Teranet dataset (filtered to include only GTHA records), ordered by date (from earliest to latest) and `pin`\n",
    "\n",
    "#### Order Teranet records by `registration_date` and `pin`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame was resorted by 'registration_date' and 'pin'.\n"
     ]
    }
   ],
   "source": [
    "df = df.sort_values(['registration_date', 'pin'])\n",
    "print(\"DataFrame was resorted by 'registration_date' and 'pin'.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Insert the new column `transaction_id`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New column 'transaction_id' was added to the DataFrame.\n"
     ]
    }
   ],
   "source": [
    "df.insert(0, \"transaction_id\", np.arange(len(df)))\n",
    "print(\"New column 'transaction_id' was added to the DataFrame.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attributes for display\n",
    "\n",
    "### Add attribute `date_disp`\n",
    "Since Teranet records do not carry any actual timestamp (each record has a timestamp of '00:00:00'), a new column `date_disp` is created from `registration_date` to show only dates. The new column `date_disp` has a data type of `datetime.date`, while the original column `registration_date` is stored in NumPy's `datetime64` data type, which allows more efficient datetime operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New column 'date_disp' was added to the DataFrame.\n"
     ]
    }
   ],
   "source": [
    "df['date_disp'] = df['registration_date'].dt.date\n",
    "print(\"New column 'date_disp' was added to the DataFrame.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Add attribute `price_disp`\n",
    "A new column `price_disp` is created from values of `consideration_amt` formatted to include thousands separator (_e.g.,_ '3,455,122') and stored as a string, for display purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New column 'price_disp' was added to the DataFrame.\n"
     ]
    }
   ],
   "source": [
    "df['price_disp'] = df['consideration_amt'].apply(lambda x: '{:,}'.format(x))\n",
    "print(\"New column 'price_disp' was added to the DataFrame.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add attribute `year`\n",
    "The new attribute `year` is parsed from `registration_date` and stored as a string, to simplify record grouping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New column 'year' was added to the DataFrame.\n"
     ]
    }
   ],
   "source": [
    "df['year'] = df['date_disp'].astype('str').apply(lambda x: x[:4])\n",
    "print(\"New column 'year' was added to the DataFrame.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add attribute `year_month`\n",
    "The new attribute `year_month` is parsed from `date_disp` and stored as a string, to simplify record grouping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New column 'year_month' was added to the DataFrame.\n"
     ]
    }
   ],
   "source": [
    "df['year_month'] = df['date_disp'].astype('str').apply(lambda x: x[:7])\n",
    "print(\"New column 'year_month' was added to the DataFrame.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add attribute `year3`\n",
    "The new attribute `year3` is created from the column `year` parsed for 3-year intervals (_e.g.,_ '2014-2016') and stored as a string, to simplify record grouping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New column 'year3' was added to the DataFrame. Took 532.60 seconds (8.88 minutes).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1805-1811         5\n",
       "1815-1817         6\n",
       "1819-1821         7\n",
       "1822-1824         9\n",
       "1827-1829        13\n",
       "1831-1833        10\n",
       "1834-1836         9\n",
       "1837-1839         7\n",
       "1840-1842        18\n",
       "1843-1845        19\n",
       "1846-1848        26\n",
       "1849-1851       105\n",
       "1852-1854       556\n",
       "1855-1857       276\n",
       "1858-1860        88\n",
       "1861-1863        72\n",
       "1864-1866        72\n",
       "1867-1869        82\n",
       "1870-1872       244\n",
       "1873-1875       294\n",
       "1876-1878       195\n",
       "1879-1881       282\n",
       "1882-1884       381\n",
       "1885-1887       242\n",
       "1888-1890       287\n",
       "1891-1893       302\n",
       "1894-1896       332\n",
       "1897-1899       167\n",
       "1900-1902       235\n",
       "1903-1905       735\n",
       "              ...  \n",
       "1930-1932      1223\n",
       "1933-1935       622\n",
       "1936-1938       737\n",
       "1939-1941      1197\n",
       "1942-1944      1275\n",
       "1945-1947      2652\n",
       "1948-1950      5527\n",
       "1951-1953      9236\n",
       "1954-1956     17298\n",
       "1957-1959     22497\n",
       "1960-1962     22448\n",
       "1963-1965     32891\n",
       "1966-1968     38402\n",
       "1969-1971     42036\n",
       "1972-1974     54540\n",
       "1975-1977     57857\n",
       "1978-1980     76801\n",
       "1981-1983     92407\n",
       "1984-1986    152742\n",
       "1987-1989    260608\n",
       "1990-1992    295599\n",
       "1993-1995    334528\n",
       "1996-1998    521558\n",
       "1999-2001    614471\n",
       "2002-2004    761388\n",
       "2005-2007    798539\n",
       "2008-2010    729790\n",
       "2011-2013    760386\n",
       "2014-2016    862676\n",
       "2017         218843\n",
       "Name: year3, Length: 68, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = time()\n",
    "\n",
    "df['year3'] = df['year']\n",
    "\n",
    "year_list = df['year'].unique()\n",
    "\n",
    "i = 0\n",
    "ylist = []\n",
    "for year in year_list:\n",
    "    ylist.append(year)\n",
    "    i += 1\n",
    "    if i == 3:\n",
    "        df['year3'] = df['year3'].str.replace('^' + ylist[0] + '$|^' + ylist[1] + '$|^' + ylist[2] + '$', \n",
    "                                              ylist[0] + '-' + ylist[2])\n",
    "        ylist = []\n",
    "        i = 0\n",
    "\n",
    "elapsed = time() - t\n",
    "\n",
    "print(\"New column 'year3' was added to the DataFrame. Took {0:,.2f} seconds ({1:.2f} minutes).\"\n",
    "      .format(elapsed, elapsed / 60))\n",
    "df['year3'].value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Add attribute `year5`\n",
    "The new attribute `year5` is created from the column `year` parsed for 5-year intervals (_e.g.,_ '2012-2016') and stored as a string, to simplify record grouping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New column 'year5' was added to the DataFrame. Took 318.35 seconds (5.31 minutes).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1805               1\n",
       "1809-1817         10\n",
       "1819-1823         11\n",
       "1824-1831         23\n",
       "1832-1836         14\n",
       "1837-1841         17\n",
       "1842-1846         39\n",
       "1847-1851        119\n",
       "1852-1856        743\n",
       "1857-1861        203\n",
       "1862-1866        118\n",
       "1867-1871        284\n",
       "1872-1876        421\n",
       "1877-1881        392\n",
       "1882-1886        523\n",
       "1887-1891        546\n",
       "1892-1896        475\n",
       "1897-1901        311\n",
       "1902-1906       1100\n",
       "1907-1911       1087\n",
       "1912-1916       1845\n",
       "1917-1921       1576\n",
       "1922-1926       1909\n",
       "1927-1931       2105\n",
       "1932-1936       1152\n",
       "1937-1941       1737\n",
       "1942-1946       2894\n",
       "1947-1951       9273\n",
       "1952-1956      23821\n",
       "1957-1961      36874\n",
       "1962-1966      54114\n",
       "1967-1971      67286\n",
       "1972-1976      91237\n",
       "1977-1981     128793\n",
       "1982-1986     214317\n",
       "1987-1991     450508\n",
       "1992-1996     605477\n",
       "1997-2001     970779\n",
       "2002-2006    1283035\n",
       "2007-2011    1267902\n",
       "2012-2016    1361842\n",
       "2017          218843\n",
       "Name: year5, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = time()\n",
    "\n",
    "df['year5'] = df['year']\n",
    "\n",
    "year_list = df['year'].unique()[1:] # skipping first year (1805) to match the length of a 5-year window\n",
    "\n",
    "i = 0\n",
    "ylist = []\n",
    "for year in year_list:\n",
    "    ylist.append(year)\n",
    "    i += 1\n",
    "    if i == 5:\n",
    "        df['year5'] = df['year5'].str.replace('^' + ylist[0] + '$|^' + ylist[1] + '$|^' + ylist[2] + '$|^' +\n",
    "                                              ylist[3] + '$|^' + ylist[4] + '$', \n",
    "                                              ylist[0] + '-' + ylist[4])\n",
    "        ylist = []\n",
    "        i = 0\n",
    "\n",
    "elapsed = time() - t\n",
    "\n",
    "print(\"New column 'year5' was added to the DataFrame. Took {0:,.2f} seconds ({1:.2f} minutes).\"\n",
    "      .format(elapsed, elapsed / 60))\n",
    "df['year5'].value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add attribute `year10`\n",
    "The new attribute `year10` is created from the column `year` parsed for 5-year intervals (_e.g.,_ '2014-2017') and stored as a string, to simplify record grouping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New column 'year10' was added to the DataFrame. Took 160.30 seconds (2.67 minutes).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1805               1\n",
       "1809-1823         21\n",
       "1824-1836         37\n",
       "1837-1846         56\n",
       "1847-1856        862\n",
       "1857-1866        321\n",
       "1867-1876        705\n",
       "1877-1886        915\n",
       "1887-1896       1021\n",
       "1897-1906       1411\n",
       "1907-1916       2932\n",
       "1917-1926       3485\n",
       "1927-1936       3257\n",
       "1937-1946       4631\n",
       "1947-1956      33094\n",
       "1957-1966      90988\n",
       "1967-1976     158523\n",
       "1977-1986     343110\n",
       "1987-1996    1055985\n",
       "1997-2006    2253814\n",
       "2007-2016    2629744\n",
       "2017          218843\n",
       "Name: year10, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = time()\n",
    "\n",
    "df['year10'] = df['year']\n",
    "\n",
    "year_list = df['year'].unique()[1:] # skipping first year (1805) to match the length of a 10-year window\n",
    "\n",
    "i = 0\n",
    "ylist = []\n",
    "for year in year_list:\n",
    "    ylist.append(year)\n",
    "    i += 1\n",
    "    if i == 10:\n",
    "        df['year10'] = df['year10'].str.replace('^' + ylist[0] + '$|^' + ylist[1] + '$|^' + ylist[2] + '$|^' +\n",
    "                                                ylist[3] + '$|^' + ylist[4] + '$|^' + ylist[5] + '$|^' + ylist[6] +\n",
    "                                                '$|^' + ylist[7] + '$|^' + ylist[8] + '$|^' + ylist[9] + '$', \n",
    "                                                ylist[0] + '-' + ylist[9])\n",
    "        ylist = []\n",
    "        i = 0\n",
    "\n",
    "elapsed = time() - t\n",
    "\n",
    "print(\"New column 'year10' was added to the DataFrame. Took {0:,.2f} seconds ({1:.2f} minutes).\"\n",
    "      .format(elapsed, elapsed / 60))\n",
    "df['year10'].value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Add attribute `xy`\n",
    "\n",
    "The new attribute `xy` is produced by concatenating `x` and `y` together (_e.g.,_ '-79.9774202446447_43.203290987723'), it can be used to identify and group records by their coordinate pairs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New column 'xy' was added to the DataFrame.\n"
     ]
    }
   ],
   "source": [
    "df['xy'] = df['x'].astype('str') + '_' + df['y'].astype('str')\n",
    "print(\"New column 'xy' was added to the DataFrame.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correction of `consideration_amt` for inflation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Exploratory attributes\n",
    "\n",
    "### Add column `total_sales`\n",
    "Total records for each pin, generated as a separate DataFrame `df_pin` which represents Teranet records grouped and indexed by `pin`.\n",
    "\n",
    "`total_sales_pin` is added as a new column for Teranet records via a merge operation on `pin`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "New column 'pin_total_sales' added to the DataFrame!\n",
      "took 36.42 seconds.\n",
      "\n",
      "New column 'xy_total_sales' added to the DataFrame!\n",
      "took 30.06 seconds.\n"
     ]
    }
   ],
   "source": [
    "# group records by `pin`\n",
    "t = time()\n",
    "pin_counts = \\\n",
    "    df.groupby('pin')['consideration_amt'].count()\n",
    "pin_counts.name = 'pin_total_sales'\n",
    "df = pd.merge(df, pin_counts, on='pin')\n",
    "elapsed = time() - t\n",
    "print(\"\\nNew column 'pin_total_sales' \"\n",
    "      \"added to the DataFrame!\"\n",
    "      \"\\ntook {0:.2f} seconds.\".format(elapsed))\n",
    "\n",
    "# group records by `xy` coordinate pairs\n",
    "t = time()\n",
    "xy_counts = \\\n",
    "    df.groupby('xy')['consideration_amt'].count()\n",
    "xy_counts.name = 'xy_total_sales'\n",
    "df = pd.merge(df, xy_counts, on='xy')\n",
    "elapsed = time() - t\n",
    "print(\"\\nNew column 'xy_total_sales' \"\n",
    "      \"added to the DataFrame!\"\n",
    "      \"\\ntook {0:.2f} seconds.\".format(elapsed))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add column `prev_sales`\n",
    "New columns are added to Teranet records capturing, for each transaction, a rolling count of previous records from this `pin` or `xy` coordinate pair."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "New column 'pin_prev_sales' added to the DataFrame!\n",
      "took 18.08 seconds.\n",
      "\n",
      "New column 'xy_prev_sales' added to the DataFrame!\n",
      "took 25.12 seconds.\n"
     ]
    }
   ],
   "source": [
    "df['count'] = 1 # used to produce rolling counts per `pin` and `xy`\n",
    "\n",
    "# group by `pin`\n",
    "t = time()\n",
    "df['pin_prev_sales'] = \\\n",
    "    df.sort_values(['pin', 'registration_date'])\\\n",
    "    .groupby('pin')['count'].cumsum() - 1\n",
    "elapsed = time() - t\n",
    "print(\"\\nNew column 'pin_prev_sales' \"\n",
    "      \"added to the DataFrame!\"\n",
    "      \"\\ntook {0:.2f} seconds.\".format(elapsed))\n",
    "\n",
    "# group by xy pairs\n",
    "t = time()\n",
    "df['xy_prev_sales'] = \\\n",
    "    df.sort_values(['xy', 'registration_date'])\\\n",
    "    .groupby('xy')['count'].cumsum() - 1\n",
    "elapsed = time() - t\n",
    "print(\"\\nNew column 'xy_prev_sales' \"\n",
    "      \"added to the DataFrame!\"\n",
    "      \"\\ntook {0:.2f} seconds.\".format(elapsed))\n",
    "\n",
    "df = df.drop('count', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add columns `price_cum_sum` and `price_pct_change`\n",
    "New columns are added to Teranet records capturing, for each transaction, a rolling sum of price from previous records from this `pin` or `xy` coordinate pair, and `pct_change` compared to previous transaction from this `pin` or `xy` pair."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "New column 'pin_price_cum_sum' added to the DataFrame!\n",
      "took 12.62 seconds.\n",
      "\n",
      "New column 'xy_price_cum_sum' added to the DataFrame!\n",
      "took 25.20 seconds.\n",
      "\n",
      "New column 'pin_price_pct_change' added to the DataFrame!\n",
      "took 14.20 seconds.\n",
      "\n",
      "New column 'xy_price_pct_change' added to the DataFrame!\n",
      "took 26.48 seconds.\n"
     ]
    }
   ],
   "source": [
    "# `price_cum_sum`\n",
    "# group records by `pin`\n",
    "t = time()\n",
    "df['pin_price_cum_sum'] = \\\n",
    "    df.sort_values(['pin', 'registration_date'])\\\n",
    "    .groupby('pin')['consideration_amt'].cumsum()\n",
    "elapsed = time() - t\n",
    "print(\"\\nNew column 'pin_price_cum_sum' \"\n",
    "      \"added to the DataFrame!\"\n",
    "      \"\\ntook {0:.2f} seconds.\".format(elapsed))\n",
    "# group records by `xy` pairs\n",
    "t = time()\n",
    "df['xy_price_cum_sum'] = \\\n",
    "    df.sort_values(['xy', 'registration_date'])\\\n",
    "    .groupby('xy')['consideration_amt'].cumsum()\n",
    "elapsed = time() - t\n",
    "print(\"\\nNew column 'xy_price_cum_sum' \"\n",
    "      \"added to the DataFrame!\"\n",
    "      \"\\ntook {0:.2f} seconds.\".format(elapsed))\n",
    "\n",
    "# `price_pct_change`\n",
    "# group records by `pin`\n",
    "t = time()\n",
    "df['pin_price_pct_change'] = \\\n",
    "    df.sort_values(['pin', 'registration_date'])\\\n",
    "    .groupby('pin')['consideration_amt'].pct_change()\n",
    "elapsed = time() - t\n",
    "print(\"\\nNew column 'pin_price_pct_change' \"\n",
    "      \"added to the DataFrame!\"\n",
    "      \"\\ntook {0:.2f} seconds.\".format(elapsed))\n",
    "# group records by `xy`\n",
    "t = time()\n",
    "df['xy_price_pct_change'] = \\\n",
    "    df.sort_values(['xy', 'registration_date'])\\\n",
    "    .groupby('xy')['consideration_amt'].pct_change()\n",
    "elapsed = time() - t\n",
    "print(\"\\nNew column 'xy_price_pct_change' \"\n",
    "      \"added to the DataFrame!\"\n",
    "      \"\\ntook {0:.2f} seconds.\".format(elapsed))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add column `price_da_pct_change`\n",
    "New column is added to Teranet records capturing, for each transaction, percentage change in price compared to the previous record from this `da_id`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "New column 'price_da_pct_change' added to the DataFrame!\n",
      "took 11.85 seconds.\n"
     ]
    }
   ],
   "source": [
    "# add column 'price_da_pct_change' to Teranet records DataFrame \n",
    "t = time()\n",
    "df['price_da_pct_change'] = \\\n",
    "    df.sort_values(['dauid', 'registration_date'])\\\n",
    "    .groupby('dauid')['consideration_amt'].pct_change()\n",
    "elapsed = time() - t\n",
    "print(\"\\nNew column 'price_da_pct_change' \"\n",
    "      \"added to the DataFrame!\"\n",
    "      \"\\ntook {0:.2f} seconds.\".format(elapsed))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add columns `years_since_last_sale`\n",
    "New columns are added to Teranet records capturing, for each transaction, years passed since the previous record from this `pin` or `xy` coordinate pair."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New column 'pin_years_since_last_sale' added to the DataFrame!\n",
      "took 1323.10 seconds (22.05 minutes).\n"
     ]
    }
   ],
   "source": [
    "t = time()\n",
    "df['pin_years_since_last_sale'] = \\\n",
    "    df.sort_values(['pin', 'registration_date'])\\\n",
    "      .groupby('pin')['registration_date']\\\n",
    "        .diff().dt.days / 365\n",
    "elapsed = time() - t\n",
    "print(\"New column 'pin_years_since_last_sale' \"\n",
    "      \"added to the DataFrame!\"\n",
    "      \"\\ntook {0:.2f} seconds ({1:.2f} minutes).\".format(elapsed, elapsed / 60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New column 'xy_years_since_last_sale' added to the DataFrame!\n",
      "took 823.29 seconds (13.72 minutes).\n"
     ]
    }
   ],
   "source": [
    "t = time()\n",
    "df['xy_years_since_last_sale'] = \\\n",
    "    df.sort_values(['xy', 'registration_date'])\\\n",
    "      .groupby('xy')['registration_date']\\\n",
    "        .diff().dt.days / 365\n",
    "elapsed = time() - t\n",
    "print(\"New column 'xy_years_since_last_sale' \"\n",
    "      \"added to the DataFrame!\"\n",
    "      \"\\ntook {0:.2f} seconds ({1:.2f} minutes).\".format(elapsed, elapsed / 60))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add columns `da_days_since_last_sale` and `da_years_since_last_sale`\n",
    "New columns are added to Teranet records capturing, for each transaction, years passed since the previous record from this `pin` or `xy` coordinate pair."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New column 'da_days_since_last_sale' added to the DataFrame!\n",
      "took 17.74 seconds.\n",
      "New column 'da_years_since_last_sale' added to the DataFrame!\n",
      "took 17.61 seconds.\n"
     ]
    }
   ],
   "source": [
    "# add column 'da_days_since_last_sale' to Teranet records DataFrame \n",
    "t = time()\n",
    "df['da_days_since_last_sale'] = \\\n",
    "    df.sort_values(['dauid', 'registration_date'])\\\n",
    "      .groupby('dauid')['registration_date']\\\n",
    "        .diff().dt.days\n",
    "elapsed = time() - t\n",
    "print(\"New column 'da_days_since_last_sale' \"\n",
    "      \"added to the DataFrame!\"\n",
    "      \"\\ntook {0:.2f} seconds.\".format(elapsed))\n",
    "# add column 'da_years_since_last_sale' to Teranet records DataFrame \n",
    "t = time()\n",
    "df['da_years_since_last_sale'] = \\\n",
    "    df.sort_values(['dauid', 'registration_date'])\\\n",
    "      .groupby('dauid')['registration_date']\\\n",
    "        .diff().dt.days / 365\n",
    "elapsed = time() - t\n",
    "print(\"New column 'da_years_since_last_sale' \"\n",
    "      \"added to the DataFrame!\"\n",
    "      \"\\ntook {0:.2f} seconds.\".format(elapsed))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add columns `sale_next_6m/1y/3y` per `pin` and `xy`\n",
    "New columns are added to Teranet records capturing, for each transaction, whether there would be another transaction in the future from this `pin`, `xy`, or `da_id`\n",
    "\n",
    "Time horizons used: 6 months, 1 year, 3 years."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New columns 'pin_sale_next_..' added to the DataFrame!\n",
      "took 11.69 seconds.\n",
      "New columns 'xy_sale_next_..' added to the DataFrame!\n",
      "took 14.75 seconds.\n"
     ]
    }
   ],
   "source": [
    "# create a new column, marks True if next 'day_diff' <= 5\n",
    "# group records by `pin`\n",
    "t = time()\n",
    "df = df.sort_values(['pin', 'registration_date'])\n",
    "df['pin_sale_next_6m'] = \\\n",
    "    df['pin_years_since_last_sale'].shift(-1) <= 0.5\n",
    "df['pin_sale_next_1y'] = \\\n",
    "    df['pin_years_since_last_sale'].shift(-1) <= 1\n",
    "df['pin_sale_next_3y'] = \\\n",
    "    df['pin_years_since_last_sale'].shift(-1) <= 3\n",
    "elapsed = time() - t\n",
    "print(\"New columns 'pin_sale_next_..' \"\n",
    "      \"added to the DataFrame!\"\n",
    "      \"\\ntook {0:.2f} seconds.\".format(elapsed))\n",
    "\n",
    "# group records by `xy`\n",
    "t = time()\n",
    "df = df.sort_values(['xy', 'registration_date'])\n",
    "df['xy_sale_next_6m'] = \\\n",
    "    df['xy_years_since_last_sale'].shift(-1) <= 0.5\n",
    "df['xy_sale_next_1y'] = \\\n",
    "    df['xy_years_since_last_sale'].shift(-1) <= 1\n",
    "df['xy_sale_next_3y'] = \\\n",
    "    df['xy_years_since_last_sale'].shift(-1) <= 3\n",
    "elapsed = time() - t\n",
    "print(\"New columns 'xy_sale_next_..' \"\n",
    "      \"added to the DataFrame!\"\n",
    "      \"\\ntook {0:.2f} seconds.\".format(elapsed))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save results to a new .csv file\n",
    "Teranet dataset without NaN records and with 12 new columns is saved as:\n",
    "`data/HHSaleHistory_cleaned_v0.9_GTHA_DA_with_cols_v0.9.csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['transaction_id', 'lro_num', 'pin', 'consideration_amt',\n",
       "       'registration_date', 'postal_code', 'unitno', 'street_name',\n",
       "       'street_designation', 'street_direction', 'municipality',\n",
       "       'street_number', 'x', 'y', 'da_objectid', 'dauid', 'csdname',\n",
       "       'taz_objectid', 'taz_o', 'street_name_raw', 'date_disp', 'price_disp',\n",
       "       'year', 'year_month', 'year3', 'year5', 'year10', 'xy',\n",
       "       'pin_total_sales', 'xy_total_sales', 'pin_prev_sales', 'xy_prev_sales',\n",
       "       'pin_price_cum_sum', 'xy_price_cum_sum', 'pin_price_pct_change',\n",
       "       'xy_price_pct_change', 'price_da_pct_change',\n",
       "       'pin_years_since_last_sale', 'xy_years_since_last_sale',\n",
       "       'da_days_since_last_sale', 'da_years_since_last_sale',\n",
       "       'pin_sale_next_6m', 'pin_sale_next_1y', 'pin_sale_next_3y',\n",
       "       'xy_sale_next_6m', 'xy_sale_next_1y', 'xy_sale_next_3y'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame saved to file:\n",
      " ../../data/teranet/Teranet_new_cols.csv \n",
      "took 734.28 seconds (12.24 minutes).\n"
     ]
    }
   ],
   "source": [
    "save_path = data_path + 'Teranet_new_cols.csv'\n",
    "t = time()\n",
    "df.to_csv(save_path, index=False)\n",
    "elapsed = time() - t\n",
    "print(\"DataFrame saved to file:\\n\", save_path,\n",
    "      \"\\ntook {0:.2f} seconds ({1:.2f} minutes).\".format(elapsed, elapsed / 60))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
